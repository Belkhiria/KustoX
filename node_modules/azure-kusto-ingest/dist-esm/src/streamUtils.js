"use strict";
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.readableToStream = exports.tryStreamToArray = exports.tryFileToBuffer = exports.fileToStream = void 0;
const fs_1 = __importDefault(require("fs"));
const stream_1 = require("stream");
const stream_array_1 = __importDefault(require("stream-array"));
const descriptors_1 = require("./descriptors");
// Returns fs.ReadStream for node and NodeJS.ReadableStream in browser
const fileToStream = (fileDescriptor) => {
    const streamFs = fs_1.default.createReadStream(fileDescriptor.file);
    const compressionType = fileDescriptor.zipped ? descriptors_1.CompressionType.GZIP : descriptors_1.CompressionType.None;
    return Promise.resolve(new descriptors_1.StreamDescriptor(streamFs, fileDescriptor.sourceId, compressionType));
};
exports.fileToStream = fileToStream;
// Used in managed streaming where we buffer the file to memory for retries
const tryFileToBuffer = async (fileDescriptor) => {
    try {
        const buffer = fs_1.default.readFileSync(fileDescriptor.file);
        const compressionType = fileDescriptor.zipped ? descriptors_1.CompressionType.GZIP : descriptors_1.CompressionType.None;
        return new descriptors_1.StreamDescriptor(buffer, fileDescriptor.sourceId, compressionType);
    }
    catch (error) {
        return await (0, exports.fileToStream)(fileDescriptor);
    }
};
exports.tryFileToBuffer = tryFileToBuffer;
const mergeStreams = (...streams) => {
    let pass = new stream_1.PassThrough();
    let waiting = streams.length;
    for (const stream of streams) {
        pass = stream.pipe(pass, { end: false });
        stream.once("end", () => --waiting === 0 && pass.emit("end"));
    }
    return pass;
};
const tryStreamToArray = async (stream, maxBufferSize) => {
    if (stream instanceof Buffer) {
        return stream;
    }
    return await new Promise((resolve, reject) => {
        const result = [];
        const endListener = () => resolve(Buffer.concat(result));
        const dataHandler = (chunk) => {
            try {
                result.push(chunk);
                if (result.reduce((sum, b) => sum + b.length, 0) > maxBufferSize) {
                    stream.removeListener("data", dataHandler);
                    stream.removeListener("end", endListener);
                    resolve(mergeStreams((0, stream_array_1.default)(result), stream));
                }
            }
            catch (e) {
                reject(e);
            }
        };
        stream.on("data", dataHandler);
        stream.on("end", endListener);
    });
};
exports.tryStreamToArray = tryStreamToArray;
const readableToStream = (stream) => {
    return (0, stream_array_1.default)([stream]);
};
exports.readableToStream = readableToStream;
//# sourceMappingURL=streamUtils.js.map